dataset:
  args:
    root: data/
    train: true
  type: RQP4
loss_function:
  args: {}
  type: MahalanobisLoss
network:
  args:
    hidden_features:
    - 32
    - 16
  type: SimpleAutoencoder
optimizer:
  args:
    amsgrad: true
    lr: 0.001
    weight_decay: 0
  type: Adam
scheduler:
  args:
    gamma: 0.9
    step_size: 200
  type: StepLR
trainer:
  args:
    batch_size: 16
    checkpoint_freq: 150
    checkpoint_start: 50
    max_epochs: 1000
    shuffle: true
    valid_split: 0.3
  type: MMSELossTrainer
